{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\nUsing TensorFlow backend.\n"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#%load_ext line_profiler\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "sess_config = tf.ConfigProto()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "COCO_DATA = 'data/coco/'\n",
    "MASK_RCNN_MODEL_PATH = 'lib/Mask_RCNN/'\n",
    "\n",
    "if MASK_RCNN_MODEL_PATH not in sys.path:\n",
    "    sys.path.append(MASK_RCNN_MODEL_PATH)\n",
    "    \n",
    "from samples.coco import coco\n",
    "from mrcnn import utils\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "    \n",
    "from lib import utils as siamese_utils\n",
    "from lib import model as siamese_model\n",
    "from lib import config as siamese_config\n",
    "   \n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import imgaug\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_classes = coco_nopascal_classes\n",
    "train_classes = np.array(range(1,81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loading annotations into memory...\nDone (t=15.21s)\ncreating index...\nindex created!\nloading annotations into memory...\nDone (t=0.45s)\ncreating index...\nindex created!\n"
    }
   ],
   "source": [
    "# Load COCO/train dataset\n",
    "coco_train = siamese_utils.IndexedCocoDataset()\n",
    "coco_train.load_coco(COCO_DATA, subset=\"train\", year=\"2017\")\n",
    "coco_train.prepare()\n",
    "coco_train.build_indices()\n",
    "coco_train.ACTIVE_CLASSES = train_classes\n",
    "\n",
    "# Load COCO/val dataset\n",
    "coco_val = siamese_utils.IndexedCocoDataset()\n",
    "coco_val.load_coco(COCO_DATA, subset=\"val\", year=\"2017\")\n",
    "coco_val.prepare()\n",
    "coco_val.build_indices()\n",
    "coco_val.ACTIVE_CLASSES = train_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nConfigurations:\nBACKBONE                       resnet50\nBACKBONE_STRIDES               [4, 8, 16, 32, 64]\nBATCH_SIZE                     6\nBBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\nCHECKPOINT_DIR                 checkpoints/\nCOMPUTE_BACKBONE_SHAPE         None\nDETECTION_MAX_INSTANCES        30\nDETECTION_MIN_CONFIDENCE       0.7\nDETECTION_NMS_THRESHOLD        0.5\nEXPERIMENT                     example\nFPN_CLASSIF_FC_LAYERS_SIZE     512\nFPN_FEATUREMAPS                256\nGPU_COUNT                      1\nGRADIENT_CLIP_NORM             5.0\nIMAGES_PER_GPU                 6\nIMAGE_MAX_DIM                  512\nIMAGE_META_SIZE                14\nIMAGE_MIN_DIM                  400\nIMAGE_MIN_SCALE                0\nIMAGE_RESIZE_MODE              square\nIMAGE_SHAPE                    [512 512   3]\nLEARNING_MOMENTUM              0.9\nLEARNING_RATE                  0.02\nLOSS_WEIGHTS                   {'rpn_class_loss': 2.0, 'rpn_bbox_loss': 0.1, 'mrcnn_class_loss': 2.0, 'mrcnn_bbox_loss': 0.5, 'mrcnn_mask_loss': 1.0}\nMASK_POOL_SIZE                 14\nMASK_SHAPE                     [28, 28]\nMAX_GT_INSTANCES               30\nMEAN_PIXEL                     [123.7 116.8 103.9]\nMINI_MASK_SHAPE                (56, 56)\nMODEL                          mrcnn\nNAME                           coco\nNUM_CLASSES                    2\nNUM_TARGETS                    1\nPOOL_SIZE                      7\nPOST_NMS_ROIS_INFERENCE        500\nPOST_NMS_ROIS_TRAINING         500\nROI_POSITIVE_RATIO             0.33\nRPN_ANCHOR_RATIOS              [0.5, 1, 2]\nRPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\nRPN_ANCHOR_STRIDE              1\nRPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\nRPN_NMS_THRESHOLD              0.7\nRPN_TRAIN_ANCHORS_PER_IMAGE    64\nSTEPS_PER_EPOCH                1000\nTARGET_MAX_DIM                 96\nTARGET_MIN_DIM                 75\nTARGET_PADDING                 True\nTARGET_SHAPE                   [96 96  3]\nTOP_DOWN_PYRAMID_SIZE          256\nTRAIN_BN                       False\nTRAIN_ROIS_PER_IMAGE           100\nUSE_MINI_MASK                  True\nUSE_RPN_ROIS                   True\nVALIDATION_STEPS               50\nWEIGHT_DECAY                   0.0001\n"
    }
   ],
   "source": [
    "class TrainConfig(siamese_config.Config):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 6 # A 8GB GPU is needed for a batch_size of 6\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    NAME = 'coco'\n",
    "    EXPERIMENT = 'example'\n",
    "    CHECKPOINT_DIR = 'checkpoints/'\n",
    "    # Adapt loss weights\n",
    "    LOSS_WEIGHTS = {'rpn_class_loss': 2.0, \n",
    "                    'rpn_bbox_loss': 0.1, \n",
    "                    'mrcnn_class_loss': 2.0, \n",
    "                    'mrcnn_bbox_loss': 0.5, \n",
    "                    'mrcnn_mask_loss': 1.0}\n",
    "    \n",
    "config = TrainConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /home/pavlo/miniconda3/envs/app/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
    }
   ],
   "source": [
    "# Create model object in inference mode.\n",
    "model = siamese_model.SiameseMaskRCNN(mode=\"training\", model_dir=MODEL_DIR, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_schedule = OrderedDict()\n",
    "train_schedule[1] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"heads\"}\n",
    "train_schedule[120] = {\"learning_rate\": config.LEARNING_RATE, \"layers\": \"all\"}\n",
    "train_schedule[160] = {\"learning_rate\": config.LEARNING_RATE/10, \"layers\": \"all\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "initializing from imagenet weights ...\n"
    }
   ],
   "source": [
    "# Load weights trained on Imagenet\n",
    "try: \n",
    "    model.load_latest_checkpoint(train_schedule=train_schedule)\n",
    "except:\n",
    "    model.load_imagenet_weights(pretraining='imagenet-687')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs, parameters in train_schedule.items():\n",
    "    print(\"\")\n",
    "    print(\"training layers {} until epoch {} with learning_rate {}\".format(parameters[\"layers\"], \n",
    "                                                                          epochs, \n",
    "                                                                          parameters[\"learning_rate\"]))\n",
    "    model.train(coco_train, coco_val, \n",
    "                learning_rate=parameters[\"learning_rate\"], \n",
    "                epochs=epochs, \n",
    "                layers=parameters[\"layers\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('app': conda)",
   "language": "python",
   "name": "python361064bitappcondaafbfa5316b674f6ba6f94b0479f5fd37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}