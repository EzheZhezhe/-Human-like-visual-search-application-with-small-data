{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Human-like Visual Search Application with small data\n",
    "<img src=\"assets/App.jpg\" width=\"1600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop materials\n",
    "\n",
    "[GitHub repository](https://github.com/EzheZhezhe/Small_data_visual_search_app)\n",
    "\n",
    "\"**README.MD**\" and  \"**environment.yml**\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Workshop structure\n",
    "\n",
    "0. Introduction\n",
    "1. Building blocks of Siamese Mask R-CNN\n",
    "2. Siamese Mask R-CNN single deployment with FastAPI\n",
    "3. Known limitations and possible improvements\n",
    "4. Conclusions and Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.Introduction\n",
    "\n",
    "## About me\n",
    "**Alyona Galyeva**: [Principal Data Solutions Engineer at LINKIT](https://www.linkit.nl/en) and [Organiser at PyLadies Amsterdam](https://amsterdam.pyladies.com/)\n",
    "\n",
    "Former Machine Learning Engineer\n",
    "\n",
    "<img src=\"assets/PyLadies1.jpg\" width=\"800\">  <img src=\"assets/PyLadies2.jpg\" width=\"800\">  <img src=\"assets/PyLadies3.jpg\" width=\"800\">  <img src=\"assets/PyLadies4.png\" width=\"800\">\n",
    "\n",
    "Feel free to contact me via LinkedIn: https://www.linkedin.com/in/alyonagalyeva/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into the deepest depths of Siamese Mask R-CNN, let's briefly recap what are the common Computer Vision tasks\n",
    "\n",
    "<img src=\"assets/ComputerVisionTasks.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what is a Siamese neural network then?\n",
    "\n",
    "<img src=\"assets/siamese.png\" width=\"1000\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, and what about Meta-learning?\n",
    "\n",
    "<img src=\"assets/Meta.jpg\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Building blocks of Siamese Mask R-CNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inevitable step to download all required libraries\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import imgaug\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "sess_config = tf.ConfigProto()\n",
    "\n",
    "COCO_DATA = os.getenv(\"COCO_DATA\")\n",
    "MASK_RCNN_MODEL_PATH = os.getenv(\"MASK_RCNN_MODEL_PATH\")\n",
    "MODEL_DIR = os.getenv(\"MODEL_DIR\")\n",
    "\n",
    "if MASK_RCNN_MODEL_PATH not in sys.path:\n",
    "    sys.path.append(MASK_RCNN_MODEL_PATH)\n",
    "    \n",
    "from samples.coco import coco\n",
    "\n",
    "from mrcnn import utils\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "    \n",
    "from lib import utils as siamese_utils\n",
    "from lib import model as siamese_model\n",
    "from lib import config as siamese_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSCOCO Dataset\n",
    "\n",
    "**What is MSCOCO?**\n",
    "\n",
    "COCO is a large-scale object detection, segmentation, and captioning dataset. COCO has several features:\n",
    "\n",
    "* Object segmentation\n",
    "* Recognition in context\n",
    "* Superpixel stuff segmentation\n",
    "* 330K images (>200K labeled)\n",
    "* 1.5 million object instances\n",
    "* 80 object categories\n",
    "* 91 stuff categories\n",
    "* 5 captions per image\n",
    "* 250,000 people with keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categories that belong to one_shot_classes:\n",
    "one_shot_classes = np.array([4*i + 1 for i in range(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/CategoriesSplit.png\" width=\"1400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index COCO/val dataset\n",
    "coco_val = siamese_utils.IndexedCocoDataset()\n",
    "coco_object = coco_val.load_coco(COCO_DATA, subset=\"val\", year=\"2017\", return_coco=True)\n",
    "coco_val.prepare()\n",
    "coco_val.build_indices()\n",
    "coco_val.ACTIVE_CLASSES = one_shot_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/siamese-mask-rcnn.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallEvalConfig(siamese_config.Config):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    NAME = 'coco'\n",
    "    EXPERIMENT = 'evaluation'\n",
    "    CHECKPOINT_DIR = 'checkpoints/'\n",
    "    NUM_TARGETS = 1\n",
    "\n",
    "class LargeEvalConfig(siamese_config.Config):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    NAME = 'coco'\n",
    "    EXPERIMENT = 'evaluation'\n",
    "    CHECKPOINT_DIR = 'checkpoints/'\n",
    "    NUM_TARGETS = 1\n",
    "    \n",
    "    # Large image sizes\n",
    "    TARGET_MAX_DIM = 192\n",
    "    TARGET_MIN_DIM = 150\n",
    "    IMAGE_MIN_DIM = 800\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "    # Large model size\n",
    "    FPN_CLASSIF_FC_LAYERS_SIZE = 1024\n",
    "    FPN_FEATUREMAPS = 256\n",
    "    # Large number of rois at all stages\n",
    "    RPN_ANCHOR_STRIDE = 1\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 256\n",
    "    POST_NMS_ROIS_TRAINING = 2000\n",
    "    POST_NMS_ROIS_INFERENCE = 1000\n",
    "    TRAIN_ROIS_PER_IMAGE = 200\n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "    MAX_GT_INSTANCES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's pick a model size\n",
    "\n",
    "#model_size = 'large'\n",
    "model_size = 'small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create config based on the chosen model size\n",
    "if model_size == 'small':\n",
    "    config = SmallEvalConfig()\n",
    "elif model_size == 'large':\n",
    "    config = LargeEvalConfig()\n",
    "    \n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select checkpoints\n",
    "if model_size == 'small':\n",
    "    checkpoint = 'checkpoints/small_siamese_mrcnn_0160.h5'\n",
    "elif model_size == 'large':\n",
    "    checkpoint = 'checkpoints/large_siamese_mrcnn_0320.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what is under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home assignment\n",
    "\n",
    "Investigate the [original article](https://arxiv.org/pdf/1811.11507.pdf) and the source code in `/lib` folder and think over what can be improved and optimized for better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Siamese Mask R-CNN single deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object in inference mode.\n",
    "model = siamese_model.SiameseMaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "model.load_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select category\n",
    "category = 15\n",
    "image_id = np.random.choice(coco_val.category_image_index[category])\n",
    "# Load target\n",
    "target = siamese_utils.get_one_target(category, coco_val, config)\n",
    "# Load image\n",
    "image = coco_val.load_image(image_id)\n",
    "\n",
    "# Run detection\n",
    "results = model.detect([[target]], [image], verbose=0)\n",
    "r = results[0]\n",
    "# Display results\n",
    "siamese_utils.display_results(target, image, r['rois'], r['masks'], r['class_ids'], r['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Home assignment\n",
    "\n",
    "lorem ipsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Known limitations and possible improvements\n",
    "\n",
    "**Known limitations:**\n",
    "- easy to implement\n",
    "- can keep the model structure\n",
    "- can learn to ignore many new types of noise\n",
    "- can combine samples from different \n",
    "\n",
    "**Possible improvements:**\n",
    "- very different types may still succeed\n",
    "- needed amount oftraining data is unclear\n",
    "- when overdone, may hurt \n",
    "- is hard to measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home assignment\n",
    "\n",
    "1. lorem ipsum\n",
    "2. lorem ipsum\n",
    "\n",
    "*Bonus:* on step 2 lorem ipsum\n",
    "\n",
    "*Future tip:* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Conclusions and Next steps\n",
    "\n",
    "- lorem ipsum\n",
    "- lorem ipsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you for your attention!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('app': conda)",
   "language": "python",
   "name": "python361064bitappcondaafbfa5316b674f6ba6f94b0479f5fd37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}